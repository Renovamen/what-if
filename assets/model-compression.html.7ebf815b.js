import{d as e}from"./app.d4989d48.js";import{_ as r}from"./plugin-vue_export-helper.21dcd24c.js";const o={},n=e('<h1 id="model-compression" tabindex="-1"><a class="header-anchor" href="#model-compression" aria-hidden="true">#</a> Model Compression</h1><h2 id="other-awesome-lists" tabindex="-1"><a class="header-anchor" href="#other-awesome-lists" aria-hidden="true">#</a> Other Awesome Lists</h2><ul><li><a href="https://github.com/he-y/Awesome-Pruning" target="_blank" rel="noopener noreferrer">he-y/Awesome-Pruning</a></li></ul><h2 id="model-pruning" tabindex="-1"><a class="header-anchor" href="#model-pruning" aria-hidden="true">#</a> Model Pruning</h2><ul><li><p><strong>Learning Efficient Convolutional Networks through Network Slimming.</strong> <em>Zhuang Liu, et al.</em> ICCV 2017. <a href="https://arxiv.org/pdf/1708.06519" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/liuzhuang13/slimming" target="_blank" rel="noopener noreferrer">[Code]</a></p></li><li><p><strong>Pruning Filters For Efficient ConvNets.</strong> <em>Hao Li, et al.</em> ICLR 2017. <a href="https://arxiv.org/pdf/1608.08710" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/tyui592/Pruning_filters_for_efficient_convnets" target="_blank" rel="noopener noreferrer">[Code(3rd)]</a></p></li><li><p><strong>To Prune, or Not to Prune: Exploring the Efficacy of Pruning for Model Compression.</strong> <em>Michael Zhu, et al.</em> ICLR 2018 Workshop. <a href="https://arxiv.org/pdf/1710.01878.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li><li><p><strong>NISP: Pruning Networks using Neuron Importance Score Propagation.</strong> <em>Ruichi Yu, et al.</em> CVPR 2018. <a href="https://arxiv.org/pdf/1711.05908" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li></ul>',5);function t(a,i){return n}var h=r(o,[["render",t]]);export{h as default};
