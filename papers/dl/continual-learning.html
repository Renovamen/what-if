<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Continual Learning | What if?</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/favicon.svg">
    <meta name="description" content="Renovamen's messy notebook.">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    
    <link rel="preload" href="/assets/css/0.styles.47cd13c8.css" as="style"><link rel="preload" href="/assets/js/app.533ef6c9.js" as="script"><link rel="preload" href="/assets/js/4.6e80d1d8.js" as="script"><link rel="preload" href="/assets/js/1.e1491037.js" as="script"><link rel="preload" href="/assets/js/2.9f3548ca.js" as="script"><link rel="preload" href="/assets/js/65.6fc6b29d.js" as="script"><link rel="prefetch" href="/assets/js/10.c439189a.js"><link rel="prefetch" href="/assets/js/11.b052c076.js"><link rel="prefetch" href="/assets/js/12.dc188ca8.js"><link rel="prefetch" href="/assets/js/13.1420baf4.js"><link rel="prefetch" href="/assets/js/14.4f4fe58b.js"><link rel="prefetch" href="/assets/js/15.37fed6de.js"><link rel="prefetch" href="/assets/js/16.9cf03a2d.js"><link rel="prefetch" href="/assets/js/17.52ea74c3.js"><link rel="prefetch" href="/assets/js/18.d9e65be5.js"><link rel="prefetch" href="/assets/js/19.a4416f18.js"><link rel="prefetch" href="/assets/js/20.11cc597d.js"><link rel="prefetch" href="/assets/js/21.e94642bd.js"><link rel="prefetch" href="/assets/js/22.5702af77.js"><link rel="prefetch" href="/assets/js/23.2dc5b482.js"><link rel="prefetch" href="/assets/js/24.eb328963.js"><link rel="prefetch" href="/assets/js/25.cc8a5c3c.js"><link rel="prefetch" href="/assets/js/26.8f8c18c5.js"><link rel="prefetch" href="/assets/js/27.de5b6f28.js"><link rel="prefetch" href="/assets/js/28.ce26a4a3.js"><link rel="prefetch" href="/assets/js/29.397c44ff.js"><link rel="prefetch" href="/assets/js/30.74896791.js"><link rel="prefetch" href="/assets/js/31.209d35e0.js"><link rel="prefetch" href="/assets/js/32.772b3b9c.js"><link rel="prefetch" href="/assets/js/33.c25c94c8.js"><link rel="prefetch" href="/assets/js/34.c3c6e1b1.js"><link rel="prefetch" href="/assets/js/35.7167191b.js"><link rel="prefetch" href="/assets/js/36.3b1bd307.js"><link rel="prefetch" href="/assets/js/37.3d28a091.js"><link rel="prefetch" href="/assets/js/38.a4c3bb5f.js"><link rel="prefetch" href="/assets/js/39.926cc7cf.js"><link rel="prefetch" href="/assets/js/40.17162732.js"><link rel="prefetch" href="/assets/js/41.b93eb4ed.js"><link rel="prefetch" href="/assets/js/42.977e93f1.js"><link rel="prefetch" href="/assets/js/43.c6d9a0b8.js"><link rel="prefetch" href="/assets/js/44.15d619e5.js"><link rel="prefetch" href="/assets/js/45.fdfb1507.js"><link rel="prefetch" href="/assets/js/46.754f64f6.js"><link rel="prefetch" href="/assets/js/47.efff60c8.js"><link rel="prefetch" href="/assets/js/48.67d0fb37.js"><link rel="prefetch" href="/assets/js/49.16cbbca9.js"><link rel="prefetch" href="/assets/js/5.5effdc9e.js"><link rel="prefetch" href="/assets/js/50.d6e4a5f8.js"><link rel="prefetch" href="/assets/js/51.7e1ee440.js"><link rel="prefetch" href="/assets/js/52.7728ae68.js"><link rel="prefetch" href="/assets/js/53.66997061.js"><link rel="prefetch" href="/assets/js/54.66b9f3b0.js"><link rel="prefetch" href="/assets/js/55.27ae2e62.js"><link rel="prefetch" href="/assets/js/56.7b7f4220.js"><link rel="prefetch" href="/assets/js/57.c7096476.js"><link rel="prefetch" href="/assets/js/58.921f228e.js"><link rel="prefetch" href="/assets/js/59.67e11eee.js"><link rel="prefetch" href="/assets/js/6.7a646bd6.js"><link rel="prefetch" href="/assets/js/60.b802d781.js"><link rel="prefetch" href="/assets/js/61.8920a2e3.js"><link rel="prefetch" href="/assets/js/62.16987741.js"><link rel="prefetch" href="/assets/js/63.aedf2ef7.js"><link rel="prefetch" href="/assets/js/64.56216976.js"><link rel="prefetch" href="/assets/js/66.470acc43.js"><link rel="prefetch" href="/assets/js/67.77177ba0.js"><link rel="prefetch" href="/assets/js/68.ab2d262b.js"><link rel="prefetch" href="/assets/js/69.fa79f9ab.js"><link rel="prefetch" href="/assets/js/7.47989a17.js"><link rel="prefetch" href="/assets/js/70.6e988b4e.js"><link rel="prefetch" href="/assets/js/71.a0565443.js"><link rel="prefetch" href="/assets/js/72.27a53de3.js"><link rel="prefetch" href="/assets/js/73.56c505f4.js"><link rel="prefetch" href="/assets/js/74.85c9e676.js"><link rel="prefetch" href="/assets/js/75.c4385a87.js"><link rel="prefetch" href="/assets/js/76.bf009895.js"><link rel="prefetch" href="/assets/js/77.0ed719d2.js"><link rel="prefetch" href="/assets/js/8.3337a28d.js"><link rel="prefetch" href="/assets/js/9.6ef22756.js">
    <link rel="stylesheet" href="/assets/css/0.styles.47cd13c8.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg aria-hidden="true" width="19.2" height="19.2" viewBox="0 0 24 24" fill="currentColor" class="ov-icon" style="font-size:1.2em;"><path fill="none" d="M0 0h24v24H0z"/><path d="M3 4h18v2H3V4zm0 7h18v2H3v-2zm0 7h18v2H3v-2z"/></svg></div> <a href="/" class="home-link router-link-active"><img src="/favicon.svg" alt="What if?" class="logo"> <span class="site-name can-hide">What if?</span></a> <nav class="nav-links can-hide"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Stupid AI" class="dropdown-title"><span class="title">Stupid AI</span> <span class="arrow down"></span></button> <button type="button" aria-label="Stupid AI" class="mobile-dropdown-title"><span class="title">Stupid AI</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/ai/ml/" class="nav-link">
  Machine Learning
</a></li><li class="dropdown-item"><!----> <a href="/ai/dl/" class="nav-link">
  Deep Learning
</a></li><li class="dropdown-item"><!----> <a href="/ai/rl/" class="nav-link">
  Reinforcement Learning
</a></li><li class="dropdown-item"><!----> <a href="/ai/nlp/" class="nav-link">
  Statistical NLP
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Math" class="dropdown-title"><span class="title">Math</span> <span class="arrow down"></span></button> <button type="button" aria-label="Math" class="mobile-dropdown-title"><span class="title">Math</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/math/linear-algebra/" class="nav-link">
  Linear Algebra
</a></li><li class="dropdown-item"><!----> <a href="/math/information-theory/" class="nav-link">
  Information Theory
</a></li></ul></div></div><div class="nav-item"><a href="/papers/" class="nav-link router-link-active">
  Papers
</a></div><div class="nav-item"><a href="/snippets/" class="nav-link">
  Snippets
</a></div></nav> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-buttons can-hide"><a role="button" aria-label="Toggle light" title="Toggle light" class="toggle-mode"><svg aria-hidden="true" width="19.2" height="19.2" viewBox="-43.52 -43.52 599.04 599.04" fill="currentColor" class="ov-icon" style="font-size:1.2em;"><path d="M224 96l16-32 32-16-32-16-16-32-16 32-32 16 32 16 16 32zM80 160l26.66-53.33L160 80l-53.34-26.67L80 0 53.34 53.33 0 80l53.34 26.67L80 160zm352 128l-26.66 53.33L352 368l53.34 26.67L432 448l26.66-53.33L512 368l-53.34-26.67L432 288zm70.62-193.77L417.77 9.38C411.53 3.12 403.34 0 395.15 0c-8.19 0-16.38 3.12-22.63 9.38L9.38 372.52c-12.5 12.5-12.5 32.76 0 45.25l84.85 84.85c6.25 6.25 14.44 9.37 22.62 9.37 8.19 0 16.38-3.12 22.63-9.37l363.14-363.15c12.5-12.48 12.5-32.75 0-45.24zM359.45 203.46l-50.91-50.91 86.6-86.6 50.91 50.91-86.6 86.6z"/></svg></a> <a rel="noopener noreferrer" target="_blank" href="https://renovamen.ink"><svg aria-hidden="true" width="20.16" height="20.16" viewBox="-75.52 -43.52 599.04 599.04" fill="currentColor" class="ov-icon" style="font-size:1.26em;"><path d="M352 320c-22.608 0-43.387 7.819-59.79 20.895l-102.486-64.054a96.551 96.551 0 000-41.683l102.486-64.054C308.613 184.181 329.392 192 352 192c53.019 0 96-42.981 96-96S405.019 0 352 0s-96 42.981-96 96c0 7.158.79 14.13 2.276 20.841L155.79 180.895C139.387 167.819 118.608 160 96 160c-53.019 0-96 42.981-96 96s42.981 96 96 96c22.608 0 43.387-7.819 59.79-20.895l102.486 64.054A96.301 96.301 0 00256 416c0 53.019 42.981 96 96 96s96-42.981 96-96-42.981-96-96-96z"/></svg></a> <a rel="noopener noreferrer" target="_blank" href="https://github.com/Renovamen/what-if"><svg aria-hidden="true" width="23.04" height="23.04" viewBox="-51.52 -43.52 599.04 599.04" fill="currentColor" class="ov-icon" style="font-size:1.44em;"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Stupid AI" class="dropdown-title"><span class="title">Stupid AI</span> <span class="arrow down"></span></button> <button type="button" aria-label="Stupid AI" class="mobile-dropdown-title"><span class="title">Stupid AI</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/ai/ml/" class="nav-link">
  Machine Learning
</a></li><li class="dropdown-item"><!----> <a href="/ai/dl/" class="nav-link">
  Deep Learning
</a></li><li class="dropdown-item"><!----> <a href="/ai/rl/" class="nav-link">
  Reinforcement Learning
</a></li><li class="dropdown-item"><!----> <a href="/ai/nlp/" class="nav-link">
  Statistical NLP
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Math" class="dropdown-title"><span class="title">Math</span> <span class="arrow down"></span></button> <button type="button" aria-label="Math" class="mobile-dropdown-title"><span class="title">Math</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/math/linear-algebra/" class="nav-link">
  Linear Algebra
</a></li><li class="dropdown-item"><!----> <a href="/math/information-theory/" class="nav-link">
  Information Theory
</a></li></ul></div></div><div class="nav-item"><a href="/papers/" class="nav-link router-link-active">
  Papers
</a></div><div class="nav-item"><a href="/snippets/" class="nav-link">
  Snippets
</a></div></nav>  <ul class="sidebar-links"><li class="sidebar-header"><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>NLP</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li class="sidebar-header"><a href="/papers/nlp/kg-application.html" class="sidebar-link">Application of KGs</a></li></ul></section></li><li class="sidebar-header"><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>CV</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li class="sidebar-header"><a href="/papers/cv/image-aesthetic-assessment.html" class="sidebar-link">Image Aesthetic Assessment</a></li><li class="sidebar-header"><a href="/papers/cv/reid.html" class="sidebar-link">Person Re-Identification</a></li></ul></section></li><li class="sidebar-header"><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>DL</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li class="sidebar-header"><a href="/papers/dl/continual-learning.html" aria-current="page" class="active sidebar-link">Continual Learning</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/papers/dl/continual-learning.html#other-awesome-lists" class="sidebar-link">Other Awesome Lists</a></li><li class="sidebar-sub-header"><a href="/papers/dl/continual-learning.html#courses-tutorials" class="sidebar-link">Courses &amp; Tutorials</a></li><li class="sidebar-sub-header"><a href="/papers/dl/continual-learning.html#surveys" class="sidebar-link">Surveys</a></li><li class="sidebar-sub-header"><a href="/papers/dl/continual-learning.html#theses" class="sidebar-link">Theses</a></li><li class="sidebar-sub-header"><a href="/papers/dl/continual-learning.html#blogs-communities" class="sidebar-link">Blogs &amp; Communities</a></li><li class="sidebar-sub-header"><a href="/papers/dl/continual-learning.html#approaches" class="sidebar-link">Approaches</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/papers/dl/continual-learning.html#regularization" class="sidebar-link">Regularization</a></li><li class="sidebar-sub-header"><a href="/papers/dl/continual-learning.html#rehearsal" class="sidebar-link">Rehearsal</a></li><li class="sidebar-sub-header"><a href="/papers/dl/continual-learning.html#dynamic-expansion" class="sidebar-link">Dynamic Expansion</a></li><li class="sidebar-sub-header"><a href="/papers/dl/continual-learning.html#task-free" class="sidebar-link">Task Free</a></li><li class="sidebar-sub-header"><a href="/papers/dl/continual-learning.html#meta-learning" class="sidebar-link">+ Meta Learning</a></li><li class="sidebar-sub-header"><a href="/papers/dl/continual-learning.html#reinforcement-learning" class="sidebar-link">+ Reinforcement Learning</a></li><li class="sidebar-sub-header"><a href="/papers/dl/continual-learning.html#generative-modeling" class="sidebar-link">+ Generative Modeling</a></li><li class="sidebar-sub-header"><a href="/papers/dl/continual-learning.html#bayesian" class="sidebar-link">Bayesian</a></li><li class="sidebar-sub-header"><a href="/papers/dl/continual-learning.html#new-settings" class="sidebar-link">New Settings</a></li></ul></li><li class="sidebar-sub-header"><a href="/papers/dl/continual-learning.html#workshops" class="sidebar-link">Workshops</a></li></ul></li><li class="sidebar-header"><a href="/papers/dl/meta-learning.html" class="sidebar-link">Meta Learning / Few-Shot Learning</a></li><li class="sidebar-header"><a href="/papers/dl/model-compression.html" class="sidebar-link">Model Compression</a></li><li class="sidebar-header"><a href="/papers/dl/misc.html" class="sidebar-link">Misc</a></li></ul></section></li></ul>  <nav class="nav-buttons"><a role="button" aria-label="Toggle light" title="Toggle light" class="toggle-mode"><svg aria-hidden="true" width="19.2" height="19.2" viewBox="-43.52 -43.52 599.04 599.04" fill="currentColor" class="ov-icon" style="font-size:1.2em;"><path d="M224 96l16-32 32-16-32-16-16-32-16 32-32 16 32 16 16 32zM80 160l26.66-53.33L160 80l-53.34-26.67L80 0 53.34 53.33 0 80l53.34 26.67L80 160zm352 128l-26.66 53.33L352 368l53.34 26.67L432 448l26.66-53.33L512 368l-53.34-26.67L432 288zm70.62-193.77L417.77 9.38C411.53 3.12 403.34 0 395.15 0c-8.19 0-16.38 3.12-22.63 9.38L9.38 372.52c-12.5 12.5-12.5 32.76 0 45.25l84.85 84.85c6.25 6.25 14.44 9.37 22.62 9.37 8.19 0 16.38-3.12 22.63-9.37l363.14-363.15c12.5-12.48 12.5-32.75 0-45.24zM359.45 203.46l-50.91-50.91 86.6-86.6 50.91 50.91-86.6 86.6z"/></svg></a> <a rel="noopener noreferrer" target="_blank" href="https://renovamen.ink"><svg aria-hidden="true" width="20.16" height="20.16" viewBox="-75.52 -43.52 599.04 599.04" fill="currentColor" class="ov-icon" style="font-size:1.26em;"><path d="M352 320c-22.608 0-43.387 7.819-59.79 20.895l-102.486-64.054a96.551 96.551 0 000-41.683l102.486-64.054C308.613 184.181 329.392 192 352 192c53.019 0 96-42.981 96-96S405.019 0 352 0s-96 42.981-96 96c0 7.158.79 14.13 2.276 20.841L155.79 180.895C139.387 167.819 118.608 160 96 160c-53.019 0-96 42.981-96 96s42.981 96 96 96c22.608 0 43.387-7.819 59.79-20.895l102.486 64.054A96.301 96.301 0 00256 416c0 53.019 42.981 96 96 96s96-42.981 96-96-42.981-96-96-96z"/></svg></a> <a rel="noopener noreferrer" target="_blank" href="https://github.com/Renovamen/what-if"><svg aria-hidden="true" width="23.04" height="23.04" viewBox="-51.52 -43.52 599.04 599.04" fill="currentColor" class="ov-icon" style="font-size:1.44em;"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a></nav></aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="continual-learning"><a href="#continual-learning" class="header-anchor">#</a> Continual Learning</h1> <p>Literatures of Continual Learning (持续学习, also called Lifelong / Incremental / Cumulative Learning).</p> <h2 id="other-awesome-lists"><a href="#other-awesome-lists" class="header-anchor">#</a> Other Awesome Lists</h2> <ul><li><a href="https://wiki.continualai.org/index.html" target="_blank" rel="noopener noreferrer">ContinualAI Wiki</a></li> <li><a href="https://github.com/optimass/continual_learning_papers" target="_blank" rel="noopener noreferrer">optimass/continual_learning_papers</a></li> <li><a href="https://github.com/xialeiliu/Awesome-Incremental-Learning" target="_blank" rel="noopener noreferrer">xialeiliu/Awesome-Incremental-Learning</a></li> <li><a href="https://github.com/prprbr/awesome-lifelong-continual-learning" target="_blank" rel="noopener noreferrer">prprbr/awesome-lifelong-continual-learning</a></li> <li><a href="https://github.com/floodsung/Lifelong-Learning-Paper-List" target="_blank" rel="noopener noreferrer">floodsung/Lifelong-Learning-Paper-List</a></li></ul> <h2 id="courses-tutorials"><a href="#courses-tutorials" class="header-anchor">#</a> Courses &amp; Tutorials</h2> <ul><li><p><strong>Life Long Learning.</strong> Hung-yi Lee (李宏毅). <a href="https://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2019/Lecture/Lifelong%20Learning%20(v9).pdf" target="_blank" rel="noopener noreferrer">[Slide]</a> <a href="https://www.youtube.com/watch?v=7qT5P9KJnWo&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=25" target="_blank" rel="noopener noreferrer">[Video]</a></p></li> <li><p><a href="https://annotation-efficient-learning.github.io/" target="_blank" rel="noopener noreferrer">CVPR 2020 Tutorial - Towards Annotation-Efficient Learning: Few-Shot, Self-Supervised, and Incremental Learning Approaches</a></p></li></ul> <h2 id="surveys"><a href="#surveys" class="header-anchor">#</a> Surveys</h2> <ul><li><p><strong>Continual Lifelong Learning with Neural Networks: A Review.</strong> <em>German I. Parisi, et al.</em> Neural Networks 2019. <a href="https://arxiv.org/pdf/1802.07569.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p> <blockquote><p>A survey on different approaches (regularization / dynamic architectures / rehearsal) for continual learning.</p></blockquote></li> <li><p><strong>Three Scenarios for Continual Learning.</strong> <em>Gido M. van de Ven and Andreas S. Tolias.</em> arXiv 2019. <a href="https://arxiv.org/pdf/1904.07734.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/GMvandeVen/continual-learning" target="_blank" rel="noopener noreferrer">[Code]</a></p> <blockquote><p>A survey on three different scenarios (task / domain / class) for continual learning.</p></blockquote></li> <li><p><strong>Continual Learning: A Comparative Study on How to Defy Forgetting in Classification Tasks.</strong> <em>Matthias De Lange, et al.</em> arXiv 2019. <a href="https://arxiv.org/pdf/1909.08383.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>Continual Learning for Robotics: Definition, Framework, Learning Strategies, Opportunities and Challenges.</strong> <em>Timothée Lesort, et al.</em> Inf. Fusion 2020. <a href="https://www.sciencedirect.com/science/article/pii/S1566253519307377" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li></ul> <h2 id="theses"><a href="#theses" class="header-anchor">#</a> Theses</h2> <ul><li><p><strong>Continual Learning with Deep Architectures.</strong> <em>Vincenzo Lomonaco.</em> University of Bologna, 2019. <a href="http://amsdottorato.unibo.it/9073/1/vincenzo_lomonaco_thesis.pdf" target="_blank" rel="noopener noreferrer">[Thesis]</a></p></li> <li><p><strong>Continual Learning with Neural Networks.</strong> <em><a href="https://saynaebrahimi.github.io/" target="_blank" rel="noopener noreferrer">Sayna Ebrahimi</a>.</em> UC Berkeley, 2020. <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2020/EECS-2020-82.pdf" target="_blank" rel="noopener noreferrer">[Thesis]</a></p></li> <li><p><strong>Continual Learning: Tackling Catastrophic Forgetting in Deep Neural Networks with Replay Processes.</strong> <em>Timothée Lesort.</em> ENSTA-ParisTech, 2020. <a href="https://arxiv.org/pdf/2007.00487.pdf" target="_blank" rel="noopener noreferrer">[Thesis]</a></p></li></ul> <h2 id="blogs-communities"><a href="#blogs-communities" class="header-anchor">#</a> Blogs &amp; Communities</h2> <ul><li><p><a href="https://vlomonaco.github.io/core50/strategies.html" target="_blank" rel="noopener noreferrer">Continuous Learning Strategies (CORe50 Dataset)</a></p></li> <li><p><a href="https://medium.com/continual-ai/why-continuous-learning-is-the-key-towards-machine-intelligence-1851cb57c308" target="_blank" rel="noopener noreferrer">Why Continual Learning is the key towards Machine Intelligence.</a> <em>Vincenzo Lomonaco.</em> Medium, 2017.</p></li> <li><p><a href="https://www.continualai.org/" target="_blank" rel="noopener noreferrer">ContinualAI</a></p></li></ul> <h2 id="approaches"><a href="#approaches" class="header-anchor">#</a> Approaches</h2> <h3 id="regularization"><a href="#regularization" class="header-anchor">#</a> Regularization</h3> <p>Impose constraints on the update of the neural weights.</p> <ul><li><p><strong>Learning without Forgetting.</strong> <em>Zhizhong Li and Derek Hoiem.</em> ECCV 2016. <a href="https://arxiv.org/pdf/1606.09282.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/lizhitwo/LearningWithoutForgetting" target="_blank" rel="noopener noreferrer">[Code]</a> (LwF)</p></li> <li><p><strong>Overcoming Catastrophic Forgetting in Neural Networks.</strong> <em>James Kirkpatrick, et al.</em> PNAS 2017. <a href="https://arxiv.org/pdf/1612.00796.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> (Elastic Weight Consolidation, EWC)</p></li> <li><p><strong>Continual Learning Through Synaptic Intelligence.</strong> <em>Friedemann Zenke, et al.</em> ICML 2017. <a href="https://arxiv.org/pdf/1703.04200.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/ganguli-lab/pathint" target="_blank" rel="noopener noreferrer">[Code]</a> (Intelligent Synapses, IS)</p></li> <li><p><strong>Online Structured Laplace Approximations For Overcoming Catastrophic Forgetting.</strong> <em>Hippolyt Ritter, et al.</em> NIPS 2018. <a href="https://arxiv.org/pdf/1805.07810.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>Improving and Understanding Variational Continual Learning.</strong> <em>Siddharth Swaroop, et al.</em> NIPS 2018 Continual Learning Workshop. <a href="https://arxiv.org/pdf/1905.02099.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/nvcuong/variational-continual-learning/tree/master/improved_ddm" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Memory Aware Synapses: Learning What (Not) to Forget.</strong> <em><a href="https://homes.esat.kuleuven.be/~raljundi/index.html" target="_blank" rel="noopener noreferrer">Rahaf Aljundi</a>, et al.</em> ECCV 2018. <a href="https://arxiv.org/pdf/1711.09601.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/rahafaljundi/MAS-Memory-Aware-Synapses" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Task Agnostic Continual Learning Using Online Variational Bayes.</strong> <em>Chen Zeno, et al.</em> arXiv 2018. <a href="https://arxiv.org/pdf/1803.10123.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/igolan/bgd" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Task-Free Continual Learning.</strong> <em><a href="https://homes.esat.kuleuven.be/~raljundi/index.html" target="_blank" rel="noopener noreferrer">Rahaf Aljundi</a>, et al.</em> CVPR 2019. <a href="https://arxiv.org/pdf/1812.03596.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>Online Continual Learning with Maximally Interfered Retrieval.</strong> <em><a href="https://homes.esat.kuleuven.be/~raljundi/index.html" target="_blank" rel="noopener noreferrer">Rahaf Aljundi</a>, et al.</em> NIPS 2019. <a href="https://papers.nips.cc/paper/9357-online-continual-learning-with-maximal-interfered-retrieval.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>Uncertainty-based Continual Learning with Adaptive Regularization.</strong> <em>Hongjoon Ahn, et al.</em> NIPS 2019. <a href="https://arxiv.org/pdf/1905.11614.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/csm9493/UCL" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Efficient continual learning in neural networks with embedding regularization.</strong> <em>Jary Pomponi, et al.</em> Neurocomputing 2020. <a href="https://arxiv.org/pdf/1909.03742.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>Uncertainty-guided Ccontinual Learning with Bayesian Neural Networks.</strong> <em>Sayna Ebrahimi, et al.</em> ICLR 2020. <a href="https://arxiv.org/pdf/1906.02425.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/SaynaEbrahimi/UCB" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Continual Learning with Node-Importance based Adaptive Group Sparse Regularization.</strong> <em>Sangwon Jung, et al.</em> CVPR 2020 Workshop on Continual Learning in Computer Vision. <a href="https://arxiv.org/pdf/2003.13726.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li></ul> <h3 id="rehearsal"><a href="#rehearsal" class="header-anchor">#</a> Rehearsal</h3> <h4 id="extra-memory"><a href="#extra-memory" class="header-anchor">#</a> Extra Memory</h4> <p>Use extra memory to store data from previous tasks.</p> <ul><li><p><strong>Gradient Episodic Memory for Continual Learning.</strong> <em>David Lopez-Paz and Marc'Aurelio Ranzato.</em> NIPS 2017. <a href="https://papers.nips.cc/paper/7225-gradient-episodic-memory-for-continual-learning.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/facebookresearch/GradientEpisodicMemory" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>iCaRL: Incremental Classifier and Representation Learning.</strong> <em>Sylvestre-Alvise Rebuffi, et al.</em> CVPR 2017. <a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Rebuffi_iCaRL_Incremental_Classifier_CVPR_2017_paper.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/srebuffi/iCaRL" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Variational Continual Learning.</strong> <em>Cuong V. Nguyen, et al.</em> ICLR 2018. <a href="https://openreview.net/pdf?id=BkQqq0gRb" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/nvcuong/variational-continual-learning" target="_blank" rel="noopener noreferrer">[Code]</a> (VCL)</p></li> <li><p><strong>Experience Replay for Continual Learning.</strong> <em>David Rolnick, et al.</em> NIPS 2019. <a href="https://papers.nips.cc/paper/8327-experience-replay-for-continual-learning.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>Continual Learning with Bayesian Neural Networks for Non-Stationary Data.</strong> <em>Richard Kurle, et al.</em> ICLR 2020. <a href="https://openreview.net/pdf?id=SJlsFpVtDB" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li></ul> <h4 id="generative-replay"><a href="#generative-replay" class="header-anchor">#</a> Generative Replay</h4> <p>Mimic past data by generative models (GAN, VAE, etc).</p> <ul><li><p><strong>Continual Learning with Deep Generative Replay.</strong> <em>Hanul Shin, et al.</em> NIPS 2017. <a href="https://papers.nips.cc/paper/6892-continual-learning-with-deep-generative-replay.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>FearNet: Brain-Inspired Model for Incremental Learning.</strong> <em>Ronald Kemker and Christopher Kanan.</em> ICLR 2018. <a href="https://openreview.net/pdf?id=SJ1Xmf-Rb" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Generative Models from the perspective of Continual Learning.</strong> <em>Timothée Lesort, et al.</em> IJCNN 2019. <a href="https://arxiv.org/pdf/1812.09111.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/TLESORT/Generative_Continual_Learning" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Learning to Remember: A Synaptic Plasticity Driven Framework for Continual Learning.</strong> <em>Oleksiy Ostapenko, et al.</em> CVPR 2019. <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Ostapenko_Learning_to_Remember_A_Synaptic_Plasticity_Driven_Framework_for_Continual_CVPR_2019_paper.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/SAP-samples/machine-learning-dgm" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Continual Unsupervised Representation Learning.</strong> <em>Dushyant Rao, et al.</em> NIPS 2019. <a href="https://papers.nips.cc/paper/8981-continual-unsupervised-representation-learning.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/deepmind/deepmind-research/tree/master/curl" target="_blank" rel="noopener noreferrer">[Code]</a></p> <blockquote><p>Continual learning without task boundaries via dynamic expansion and generative replay (VAE).</p></blockquote></li></ul> <h3 id="dynamic-expansion"><a href="#dynamic-expansion" class="header-anchor">#</a> Dynamic Expansion</h3> <p>Increase in network capacity that handles new tasks without affecting learned networks.</p> <ul><li><p><strong>Net2Net: Accelerating Learning via Knowledge Transfer.</strong> <em>Tianqi Chen, et al.</em> ICLR 2016. <a href="https://arxiv.org/pdf/1511.05641.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>Progressive Neural Networks.</strong> <em>Andrei A. Rusu, et al.</em> arXiv 2016. <a href="https://arxiv.org/pdf/1606.04671.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>Expert Gate: Lifelong Learning with a Network of Experts.</strong> <em><a href="https://homes.esat.kuleuven.be/~raljundi/index.html" target="_blank" rel="noopener noreferrer">Rahaf Aljundi</a>, et al.</em> CVPR 2017. <a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Aljundi_Expert_Gate_Lifelong_CVPR_2017_paper.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/wannabeOG/ExpertNet-Pytorch" target="_blank" rel="noopener noreferrer">[Re-implementation]</a></p></li> <li><p><strong>Random Path Selection for Continual Learning.</strong> <em>Jathushan Rajasegaran, et al.</em> NIPS 2019. <a href="http://papers.nips.cc/paper/9429-random-path-selection-for-continual-learning.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/brjathu/RPSnet" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Compacting, Picking and Growing for Unforgetting Continual Learning.</strong> <em>Steven C. Y. Hung, et al.</em> NIPS 2019. <a href="https://papers.nips.cc/paper/9518-compacting-picking-and-growing-for-unforgetting-continual-learning.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/ivclab/CPG" target="_blank" rel="noopener noreferrer">[Code]</a></p> <blockquote><p>Gradual model pruning (compacting) → Train a 0-1 mask to pick weights of previous tasks (picking) → Dynamic expansion (growing)</p></blockquote></li> <li><p><strong>Continual Unsupervised Representation Learning.</strong> <em>Dushyant Rao, et al.</em> NIPS 2019. <a href="https://papers.nips.cc/paper/8981-continual-unsupervised-representation-learning.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/deepmind/deepmind-research/tree/master/curl" target="_blank" rel="noopener noreferrer">[Code]</a></p> <blockquote><p>Continual learning without task boundaries via dynamic expansion and generative replay (VAE).</p></blockquote></li> <li><p><strong>Continual Learning with Adaptive Weights (CLAW).</strong> <em>Tameem Adel, et al.</em> ICLR 2020. <a href="https://openreview.net/pdf?id=Hklso24Kwr" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning.</strong> <em>Soochan Lee, et al.</em> ICLR 2020. <a href="https://openreview.net/pdf?id=SJxSOJStPr" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/soochan-lee/CN-DPM" target="_blank" rel="noopener noreferrer">[Code]</a></p></li></ul> <h3 id="task-free"><a href="#task-free" class="header-anchor">#</a> Task Free</h3> <ul><li><p><strong>Task Agnostic Continual Learning Using Online Variational Bayes.</strong> <em>Chen Zeno, et al.</em> arXiv 2018. <a href="https://arxiv.org/pdf/1803.10123.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/igolan/bgd" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Task-Free Continual Learning.</strong> <em><a href="https://homes.esat.kuleuven.be/~raljundi/index.html" target="_blank" rel="noopener noreferrer">Rahaf Aljundi</a>, et al.</em> CVPR 2019. <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Aljundi_Task-Free_Continual_Learning_CVPR_2019_paper.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>Continual Unsupervised Representation Learning.</strong> <em>Dushyant Rao, et al.</em> NIPS 2019. <a href="https://papers.nips.cc/paper/8981-continual-unsupervised-representation-learning.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/deepmind/deepmind-research/tree/master/curl" target="_blank" rel="noopener noreferrer">[Code]</a></p> <blockquote><p>Continual learning without task boundaries via dynamic expansion (Dirichlet process) and generative replay (VAE).</p></blockquote></li> <li><p><strong>Reconciling Meta-Learning and Continual Learning with Online Mixtures of Tasks.</strong> <em>Ghassen Jerfel, et al.</em> NIPS 2019. <a href="https://arxiv.org/pdf/1812.06080.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>Continuous Meta-Learning without Tasks.</strong> <em>James Harrison, et al.</em> arXiv 2019. <a href="https://arxiv.org/pdf/1912.08866.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/StanfordASL/moca" target="_blank" rel="noopener noreferrer">[Code]</a> <a href="https://openreview.net/forum?id=r1l1myStwr" target="_blank" rel="noopener noreferrer">[OpenReview]</a></p> <blockquote><p>Integrate Bayesian online changepoint detection algorithm with existing meta-learning approaches to enable meta-learning in task-unsegmented settings.</p></blockquote></li> <li><p><strong>A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning.</strong> <em>Soochan Lee, et al.</em> ICLR 2020. <a href="https://openreview.net/pdf?id=SJxSOJStPr" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/soochan-lee/CN-DPM" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Task Agnostic Continual Learning via Meta Learning.</strong> <em>Xu He, et al.</em> ICML 2020 LifelongML Workshop. <a href="https://openreview.net/pdf?id=AeIzVxdJgeb" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li></ul> <h3 id="meta-learning"><a href="#meta-learning" class="header-anchor">#</a> + Meta Learning</h3> <p><a href="/papers/dl/meta-learning/">Here</a> is also a list of literatures for Meta Learning.</p> <ul><li><p><strong>Meta Continual Learning.</strong> <em>Risto Vuori, et al.</em> arXiv 2018. <a href="https://arxiv.org/pdf/1806.06928.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p> <blockquote><p>Train a RNN as optimizer, and the optimizer leverages information of both current and previous tasks to learn to preserve previous parameters.</p></blockquote></li> <li><p><strong>Learning to Learn without Forgetting by Maximizing Transfer and Minimizing Interference.</strong> <em>Matthew Riemer, et al.</em> ICLR 2019. <a href="https://arxiv.org/pdf/1810.11910.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/mattriemer/MER" target="_blank" rel="noopener noreferrer">[Code]</a> (Meta-Experience Replay, MER)</p> <blockquote><p>Combine Reptile (a meta-learning algorithm) with experience replay for rapidly learning the current and future experience and preserving past knowledge.</p></blockquote></li> <li><p><strong>Meta-Learning Representations for Continual Learning.</strong> <em>Khurram Javed and Martha White.</em> NIPS 2019. <a href="https://arxiv.org/pdf/1905.12588.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/khurramjaved96/mrcl" target="_blank" rel="noopener noreferrer">[Code]</a> <a href="https://sites.ualberta.ca/~kjaved/posters/mrcl.pdf" target="_blank" rel="noopener noreferrer">[Poster]</a></p></li> <li><p><strong>Reconciling Meta-Learning and Continual Learning with Online Mixtures of Tasks.</strong> <em>Ghassen Jerfel, et al.</em> NIPS 2019. <a href="https://arxiv.org/pdf/1812.06080.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>Continuous Meta-Learning without Tasks.</strong> <em>James Harrison, et al.</em> arXiv 2019. <a href="https://arxiv.org/pdf/1912.08866.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/StanfordASL/moca" target="_blank" rel="noopener noreferrer">[Code]</a> <a href="https://openreview.net/forum?id=r1l1myStwr" target="_blank" rel="noopener noreferrer">[OpenReview]</a></p> <blockquote><p>Integrate Bayesian online changepoint detection algorithm with existing meta-learning approaches to enable meta-learning in task-unsegmented settings.</p></blockquote></li> <li><p><strong>Task Agnostic Continual Learning via Meta Learning.</strong> <em>Xu He, et al.</em> ICML 2020 LifelongML Workshop. <a href="https://openreview.net/pdf?id=AeIzVxdJgeb" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li></ul> <h3 id="reinforcement-learning"><a href="#reinforcement-learning" class="header-anchor">#</a> + Reinforcement Learning</h3> <ul><li><p><strong>Reinforced Continual Learning.</strong> <em>Ju Xu and Zhanxing Zhu.</em> NIPS 2018. <a href="https://papers.nips.cc/paper/7369-reinforced-continual-learning.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/xujinfan/Reinforced-Continual-Learning" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Experience Replay for Continual Learning.</strong> <em>David Rolnick, et al.</em> NIPS 2019. <a href="https://papers.nips.cc/paper/8327-experience-replay-for-continual-learning.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li></ul> <h3 id="generative-modeling"><a href="#generative-modeling" class="header-anchor">#</a> + Generative Modeling</h3> <ul><li><p><strong>Lifelong GAN: Continual Learning for Conditional Image Generation.</strong> <em>Mengyao Zhai, et al.</em> ICCV 2019. <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhai_Lifelong_GAN_Continual_Learning_for_Conditional_Image_Generation_ICCV_2019_paper.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>Generative Models from the perspective of Continual Learning.</strong> <em>Timothée Lesort, et al.</em> IJCNN 2019. <a href="https://arxiv.org/pdf/1812.09111.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/TLESORT/Generative_Continual_Learning" target="_blank" rel="noopener noreferrer">[Code]</a></p></li></ul> <h3 id="bayesian"><a href="#bayesian" class="header-anchor">#</a> Bayesian</h3> <ul><li><p><strong>Variational Continual Learning.</strong> <em>Cuong V. Nguyen, et al.</em> ICLR 2018. <a href="https://openreview.net/pdf?id=BkQqq0gRb" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/nvcuong/variational-continual-learning" target="_blank" rel="noopener noreferrer">[Code]</a> (VCL)</p></li> <li><p><strong>Online Structured Laplace Approximations For Overcoming Catastrophic Forgetting.</strong> <em>Hippolyt Ritter, et al.</em> NIPS 2018. <a href="https://arxiv.org/pdf/1805.07810.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>Improving and Understanding Variational Continual Learning.</strong> <em>Siddharth Swaroop, et al.</em> NIPS 2018 Continual Learning Workshop. <a href="https://arxiv.org/pdf/1905.02099.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/nvcuong/variational-continual-learning/tree/master/improved_ddm" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Task Agnostic Continual Learning Using Online Variational Bayes.</strong> <em>Chen Zeno, et al.</em> arXiv 2018. <a href="https://arxiv.org/pdf/1803.10123.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/igolan/bgd" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Continual Unsupervised Representation Learning.</strong> <em>Dushyant Rao, et al.</em> NIPS 2019. <a href="https://papers.nips.cc/paper/8981-continual-unsupervised-representation-learning.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/deepmind/deepmind-research/tree/master/curl" target="_blank" rel="noopener noreferrer">[Code]</a></p> <blockquote><p>Continual learning without task boundaries via dynamic expansion and generative replay (VAE).</p></blockquote></li> <li><p><strong>Reconciling Meta-Learning and Continual Learning with Online Mixtures of Tasks.</strong> <em>Ghassen Jerfel, et al.</em> NIPS 2019. <a href="https://arxiv.org/pdf/1812.06080.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>Uncertainty-based Continual Learning with Adaptive Regularization.</strong> <em>Hongjoon Ahn, et al.</em> NIPS 2019. <a href="https://arxiv.org/pdf/1905.11614.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/csm9493/UCL" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Continuous Meta-Learning without Tasks.</strong> <em>James Harrison, et al.</em> arXiv 2019. <a href="https://arxiv.org/pdf/1912.08866.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/StanfordASL/moca" target="_blank" rel="noopener noreferrer">[Code]</a> <a href="https://openreview.net/forum?id=r1l1myStwr" target="_blank" rel="noopener noreferrer">[OpenReview]</a></p> <blockquote><p>Integrate Bayesian online changepoint detection algorithm with existing meta-learning approaches to enable meta-learning in task-unsegmented settings.</p></blockquote></li> <li><p><strong>Task Agnostic Continual Learning via Meta Learning.</strong> <em>Xu He, et al.</em> ICML 2020 LifelongML Workshop. <a href="https://openreview.net/pdf?id=AeIzVxdJgeb" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning.</strong> <em>Soochan Lee, et al.</em> ICLR 2020. <a href="https://openreview.net/pdf?id=SJxSOJStPr" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/soochan-lee/CN-DPM" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Continual Learning with Bayesian Neural Networks for Non-Stationary Data.</strong> <em>Richard Kurle, et al.</em> ICLR 2020. <a href="https://openreview.net/pdf?id=SJlsFpVtDB" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>Uncertainty-guided Ccontinual Learning with Bayesian Neural Networks.</strong> <em>Sayna Ebrahimi, et al.</em> ICLR 2020. <a href="https://arxiv.org/pdf/1906.02425.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/SaynaEbrahimi/UCB" target="_blank" rel="noopener noreferrer">[Code]</a></p></li></ul> <h3 id="new-settings"><a href="#new-settings" class="header-anchor">#</a> New Settings</h3> <ul><li><p><strong>Online Fast Adaptation and Knowledge Accumulation (OSAKA): a New Approach to Continual Learning.</strong> <em>Massimo Caccia, et al.</em> arXiv 2020. <a href="https://arxiv.org/pdf/2003.05856.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/ElementAI/osaka" target="_blank" rel="noopener noreferrer">[Code]</a></p></li> <li><p><strong>Wandering Within a World: Online Contextualized Few-Shot Learning.</strong> <em>Mengye Ren, et al.</em> arXiv 2020. <a href="https://arxiv.org/pdf/2007.04546.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a></p></li> <li><p><strong>Compositional Language Continual Learning.</strong> <em>Yuanpeng Li, et al.</em> ICLR 2020. <a href="https://openreview.net/pdf?id=rklnDgHtDS" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/yli1/CLCL" target="_blank" rel="noopener noreferrer">[Code]</a></p> <blockquote><p>Continual learning in NLP for seq2seq style tasks.</p></blockquote></li></ul> <h2 id="workshops"><a href="#workshops" class="header-anchor">#</a> Workshops</h2> <ul><li><a href="https://sites.google.com/site/cldlnips2016/submissions" target="_blank" rel="noopener noreferrer">Continual Learning and Deep Networks Workshop, NIPS 2016</a></li> <li><a href="https://erodner.github.io/continuouslearningcvpr2017/" target="_blank" rel="noopener noreferrer">Continuous and Open-Set Learning Workshop, CVPR 2017</a></li> <li><a href="https://rlabstraction2016.wixsite.com/icml-2017" target="_blank" rel="noopener noreferrer">First Lifelong Machine Learning Workshop, ICML 2017</a></li> <li><a href="https://sites.google.com/view/llarla2018/home" target="_blank" rel="noopener noreferrer">Second Lifelong Machine Learning Workshop, ICML 2018</a></li> <li><a href="https://sites.google.com/view/continual2018" target="_blank" rel="noopener noreferrer">Continual learning Workshop, NeurIPS 2018</a></li> <li><a href="https://sites.google.com/view/llarla/home" target="_blank" rel="noopener noreferrer">Third Lifelong Machine Learning Workshop, RLDM 2019</a></li> <li><a href="https://sites.google.com/view/cl-icml/organizers?authuser=0" target="_blank" rel="noopener noreferrer">Workshop on Continual Learning, ICML 2020</a></li> <li><a href="https://lifelongml.github.io/" target="_blank" rel="noopener noreferrer">4th Lifelong Machine Learning Workshop, ICML 2020</a></li></ul></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/Renovamen/what-if/edit/master/notes/papers/dl/continual-learning.md" target="_blank" rel="noopener noreferrer"><svg aria-hidden="true" width="19.2" height="19.2" viewBox="-43.52 -43.52 599.04 599.04" fill="currentColor" class="ov-icon" style="font-size:1.2em;"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg> <p>Edit this page on Github</p></a></div> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">3/29/2021, 12:36:55 PM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/papers/cv/reid.html" class="prev">
        Person Re-Identification
      </a></span> <span class="next"><a href="/papers/dl/meta-learning.html">
        Meta Learning / Few-Shot Learning
      </a>
      →
    </span></p></div> </main> <!----></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.533ef6c9.js" defer></script><script src="/assets/js/4.6e80d1d8.js" defer></script><script src="/assets/js/1.e1491037.js" defer></script><script src="/assets/js/2.9f3548ca.js" defer></script><script src="/assets/js/65.6fc6b29d.js" defer></script>
  </body>
</html>
